\section{Matice ako zobrazenia vektorov}

Uvažujme maticu $A=(a_{ij})$ typu $m \times n$; sprava ju môžeme vynásobiť vektorom (t.j. stĺpcom) typu $n \times 1$;
výsledok je opäť stĺpec typu $m \times 1$ (t.j. vektor).

Príkl.
$$ \begin{pmatrix} 1 & -3 & \frac{1}{2} \\ 0 & 4 & -2 \end{pmatrix} \begin{pmatrix} 2 \\ 0 \\ 1 \end{pmatrix} = \begin{pmatrix} \frac{3}{2} \\ -2 \end{pmatrix} $$

Týmto spôsobom máme s každou maticou $A$ typu $m \times n$ asociované zobrazenie
$$ [[A]]: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m} $$
dané predpisom $[[A]](\vec{x}) = A\vec{x}$ alebo (slovne) vynásob vektor $\vec{x} \in \mathbb{R}^{n}$ maticou $A$ zľava.
Máme teda nejaký typ matematického objektu (zobrazenie z $\mathbb{R}^n$ do $\mathbb{R}^m$) reprezentovaný iným objektom (matica typu $m \times n$).

Cieľom tohto textu je preskúmať väzbu medzi maticami a zobrazeniami, ktoré reprezentujú.
Teraz uvedieme niekoľko matíc a popíšeme zobrazenia, ktoré reprezentujú. Ak to budeme vedieť, sformulujeme aj význam toho zobrazenia - geometrický alebo iný.

\begin{priklad}[Nulové matice]
Uvažujme nulovú maticu typu $m \times n$. Aké zobrazenie $\mathbb{R}^{n} \rightarrow \mathbb{R}^{m}$ táto matica reprezentuje?
Počítajme:
$$ 
\underbrace{
\begin{pmatrix} 0 & 0 & \dots & 0 \\
0 & 0 & \dots & 0 \\
\vdots & \vdots & \vdots & \vdots \\
0 & 0 & \dots & 0 
\end{pmatrix}}
_{\R^{m\times n}}
\underbrace{
\begin{pmatrix} x_{1} \\
\vdots \\
x_{n} 
\end{pmatrix} 
}_{\in\R^n}
=
\underbrace{
\begin{pmatrix} 0 \\
\vdots \\
0 \end{pmatrix} 
}_{\R^m}
$$
$\in \mathbb{R}^{m \times n}$ \hspace{1em} $\in \mathbb{R}^{n}$ \hspace{1em} $\in \mathbb{R}^{m}$

Vidíme teda, že nulová matica reprezentuje zobrazenie z $\mathbb{R}^{n} \rightarrow \mathbb{R}^{m}$, ktoré zobrazí každý vektor z $\mathbb{R}^{n}$ na prvok $\vec{0}=(0,...,0) \in \mathbb{R}^{m}$, t.j.
konštantné zobrazenie s hodnotou $\vec{0}$. Asi nikoho neprekvapí, že toto zobrazenie sa značí $O$.
\end{priklad}

\begin{priklad}[Jednotkové matice a ich skalárne násobky]
Spomeňme si, že jednotková matica $I_n$ je diagonálna matica typu $n \times n$, ktorá má na diagonále samé 1. Preskúmajme, aké zobrazenie reprezentuje:
$$ 
\underbrace{
\begin{pmatrix} 1 & 0 & 0 & \dots & 0 \\
0 & 1 & 0 & \dots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \dots & 1 \end{pmatrix} 
}_{I_n\in\R^{n\times n}}
\underbrace{
\begin{pmatrix} a_{1} \\
a_{2} \\
\vdots \\
a_{n} \end{pmatrix}
}_{\in\R^n}
= 
\underbrace{
\begin{pmatrix} a_{1} \\
a_{2} \\
\vdots \\
a_{n} \end{pmatrix} 
}
_{\in\R^n}
$$

Vidíme teda, že $I_n \vec{x} = \vec{x}$ pre všetky vektory $\vec{x} \in \mathbb{R}^n$
a teda $I_n$ reprezentuje identické zobrazenie $\id_{\mathbb{R}^n}$:
$$
[[I_n]] = \id_{\mathbb{R}^n}.
$$
\end{priklad}
\begin{priklad}
Pozrime sa teraz na trochu všeobecnejší prípad; nech $D_{\alpha}$ je diagonálna matica typu $n \times n$, ktorá má na diagonále tú istú konštantu $\alpha \in \mathbb{R}$. Určme, aké zobrazenie takáto matica reprezentuje.
$$ \underbrace{\begin{pmatrix} \alpha & 0 & 0 & \dots & 0 \\ 0 & \alpha & 0 & \dots & 0 \\ \vdots & \vdots & \ddots & & \vdots \\ 0 & 0 & 0 & \dots & \alpha \end{pmatrix}}_{D_{\alpha} \in \mathbb{R}^{n \times n}} \underbrace{\begin{pmatrix} x_{1} \\ x_{2} \\ \vdots \\ x_{n} \end{pmatrix}}_{\in \mathbb{R}^{n}} = \underbrace{\begin{pmatrix} \alpha x_{1} \\ \alpha x_{2} \\ \vdots \\ \alpha x_{n} \end{pmatrix}}_{\in \mathbb{R}^{n}} = \alpha \vec{x} $$
(násobenie vektora sklárom)

Teda (symbolicky) 
$$
[[D_{\alpha}]](\vec{x})= \alpha\vec{x},
$$
pre všetky $\alpha \in \mathbb{R}$ a $\vec{x} \in \mathbb{R}^n$.
Všimnime si, že (keďže $D_0 = 0$ a $D_1 = I_n$) toto dostávame spätne ako špeciálne
prípady $\alpha=0, \alpha=1$:
\[
[[0]](\vec x)=[[D_0]](\vec x) = 0\vec{x} = \vec{0}
\]
\[
[[I_n]](\vec{x}) = [[D_1]](\vec{x}) = 1\vec{x} = \vec{x} = \id_{\mathbb{R}^n}(\vec{x})
\]
\end{priklad}

%D.Ú.: Popíšte zobrazenia reprezentované diagonálnymi maticami.

\begin{priklad}[Súčty a priemery]
Každá matica $A \in \mathbb{R}^{1 \times n}$ (riadok) reprezentuje zobrazenie
$[[A]]: \mathbb{R}^n \rightarrow \mathbb{R}^1$.
($\downarrow$ prvky $\mathbb{R}^1$ sú usporiadané 1-ice; $\mathbb{R}^1 = \mathbb{R}$)

Uvažujme špeciálne maticu z $\mathbb{R}^{1 \times n}$ obsahujúcu iba 1; máme
$$ (\begin{matrix} 1 & 1 & \dots & 1 \end{matrix}) \begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix} = x_1 + x_2 + \dots + x_n $$
Zobrazenie z $\mathbb{R}^n$ do $\mathbb{R}^1$ reprezentované touto maticou je teda dané jednoducho ako "súčet zložiek vektora".

Podobne $(\frac{1}{n} \dots \frac{1}{n})$ reprezentuje zobrazenie "priemer zložiek vektora".
$$ (\begin{matrix} \frac{1}{n} & \dots & \frac{1}{n} \end{matrix}) \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix} = \frac{x_1}{n} + \dots + \frac{x_n}{n} = \frac{x_1 + \dots + x_n}{n} $$
\end{priklad}

\begin{priklad}[Pravouhlá projekcia na priamku]
Vezmime si teraz maticu
$$ P = \begin{pmatrix} 1/2 & 1/2 \\ 1/2 & 1/2 \end{pmatrix} $$
Táto reprezentuje zobrazenie $\mathbb{R}^2 \rightarrow \mathbb{R}^2$. Predpis tohto zobrazenia rozpísaný do zložiek nájdeme ľahko
$$ \begin{pmatrix} \frac{1}{2} & \frac{1}{2} \\ \frac{1}{2} & \frac{1}{2} \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} \frac{1}{2}x_1 + \frac{1}{2}x_2 \\ \frac{1}{2}x_1 + \frac{1}{2}x_2 \end{pmatrix} $$
(obe zložky sú vždy rovnaké)

Pokúsme sa interpretovať toto zobrazenie geometricky; stotožníme vektory z $\mathbb{R}^2$ s vektormi v rovine prostredníctvom nejakých dvoch navzájom kolmých súradnicových osí
a určíme polohu obrazov niekoľkých vektorov.
Pre každý vektor $\vec{x}$ má $P\vec{x}$ obe zložky rovnaké. Geometricky toto znamená, že $P\vec{x}$ leží na priamke $q$ prechádzajúcej počiatkom
\begin{equation}\label{eq:q}
q = \{(t,t) : t \in \mathbb{R}\}
\end{equation}
\begin{align*}
[[P]](3,1) &= (2,2)\\
[[P]](0,0) &= (0,0)\\
[[P]](-1,-2) &= \left(-\frac{3}{2}, -\frac{3}{2}\right)
\end{align*}
\begin{center}
\begin{tikzpicture}[
    >=Stealth, % Sets the default arrow tip style
    x=1cm, y=1cm, % Sets the scale
    axis/.style={->, thick},
    vec/.style={->, thick, -{Stealth[length=2.5mm]}},
    dashline/.style={dashed, thick}
]

% --- Title Equation ---

% --- Axes and Ticks ---
\draw [axis] (-3,0) -- (4.5,0); % x-axis
\draw [axis] (0,-4) -- (0,4.5); % y-axis

% Ticks
\foreach \x in {-2,-1,1,2,3} {
    \draw (\x, 2pt) -- (\x, -2pt) node[below, yshift=-2pt] {$\x$};
}
\foreach \y in {-3,-2,-1,1,2,3} {
    \draw (2pt, \y) -- (-2pt, \y) node[left, xshift=-2pt] {$\y$};
}

% Origin Label
\node[below right, xshift=-2pt, yshift=-1pt] at (0,0) {$(0,0)$};
\node[above left, xshift=-1pt, yshift=1pt] at (0,0) {$[[P]](0,0)$};

% --- The Line q ---
\draw [red, thick] (-3.5,-3.5) -- (3.5, 3.5) node[right, xshift=2pt] {$q$};

% --- Point (3,1) and its Projection ---
\coordinate (A) at (3,1);
\coordinate (PA) at (2,2); % The projection [[P]](3,1) is at (3,3)

% Labels
\node[right, xshift=2pt] at (A) {$(3,1)$};
\node[right, xshift=3pt] at (PA) {$[[P]](3,1)$};

% Vectors
\draw [vec] (0,0) -- (A);     % Vector from origin to (3,1)
\draw [vec] (0,0) -- (PA);   % Vector from origin to [[P]](3,1)

% Dashed coordinate lines
\draw [dashline] (A) -- (A |- 0,0); % (3,1) to (3,0)
\draw [dashline] (A) -- (0,0 |- A); % (3,1) to (0,1)
\draw [dashline] (PA) -- (PA |- 0,0); % (3,3) to (3,0)
\draw [dashline] (PA) -- (0,0 |- PA); % (3,3) to (0,3)

% --- Point (-1,-2) and its Projection ---
\coordinate (B) at (-1,-2);
\coordinate (PB) at (-1.5,-1.5); % The projection is at (-1.5,-1.5)
\draw [dashline] (PB) -- (PB |- 0,0); % (3,3) to (3,0)
\draw [dashline] (PB) -- (0,0 |- PB); % (3,3) to (0,3)
\draw [vec] (0,0) -- (B);     % Vector from origin to (B)
\draw [vec] (0,0) -- (PB);     % Vector from origin to (PB)

% Label
\node[below, yshift=-2pt] at (B) {$(-1,-2)$};
\node[left, xshift=-2pt] at (PB) {$[[P]](-1,-2)$};

% Dashed coordinate lines
\draw [dashline] (B) -- (B |- 0,0); % (-1,-2) to (-1,0)
\draw [dashline] (B) -- (0,0 |- B); % (-1,-2) to (0,-2)

% Mapping
\draw [dashline,->, >=Stealth, blue] (A)--(PA);
\draw [dashline,->, >=Stealth, blue] (B)--(PB);

\end{tikzpicture}
\end{center}

Po vyskúšaní pár bodov dospejeme k hypotéze $[[P]](\vec{x})$ je priemet $\vec{x}$ na
$q$ v pravom uhle. Táto hypotéza je naozaj pravdivá. Je možné ju dokázať holými
rukami, ale rozumnejšie je odložiť jej dôkaz na neskôr, do druhého semestra, keď
budeme mať k dispozícii mocnejšie nástroje.
\end{priklad}

\begin{priklad}[Rovinná rotácia]
Uvažujme, pre $\alpha \in \langle 0, 2\pi \rangle$ maticu 
\[
L_{\alpha} = \begin{pmatrix} \cos\alpha & -\sin\alpha \\ \sin\alpha & \cos\alpha \end{pmatrix}
\]
Máme
$$ [[L_{\alpha}]](x_1, x_2) = \begin{pmatrix} \cos\alpha & -\sin\alpha \\ \sin\alpha & \cos\alpha \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} x_1 \cos\alpha - x_2 \sin\alpha \\ x_1 \sin\alpha + x_2 \cos\alpha \end{pmatrix} $$
Význam tohto zobrazenia je rotácia
proti smeru hodinových ručičiek o uhol $\alpha$ vľavo okolo počiatku.
\begin{center}
\begin{tikzpicture}
    [dashline/.style={dashed, thick}]
    % Axes
    \draw ({-pi-0.5},0) -- ({pi+0.5},0);
    \draw (0,{-pi-0.5}) -- (0,{pi+0.5});

    % Vector x
    \coordinate (X) at (2, 1.5);
    \draw[-Stealth] (0,0) -- (X) node[below right] {$\vec{x}=(x_1,x_2)$};

    % Rotated Vector L_alpha(x)
    \pgfmathsetmacro{\angle}{atan2(1.5,2)}
    \pgfmathsetmacro{\rotatedangle}{\angle + 30} % Example rotation by 30 degrees
    \pgfmathsetmacro{\rotatedx}{2.5 * cos(\rotatedangle)}
    \pgfmathsetmacro{\rotatedy}{2.5 * sin(\rotatedangle)}
    \coordinate (LX) at (\rotatedx, \rotatedy);
    \draw[-Stealth] (0,0) -- (LX) node[above] {$[[L_\alpha]](\vec{x})$};

    % Angle alpha
    \pgfmathsetmacro{\startangle}{atan2(1.5,2)}
    \pgfmathsetmacro{\endangle}{\startangle + 30}
    \draw[dotted, thick, ->, >=Stealth, blue, bend left=15] (X) arc (\startangle:\endangle:2.5);
    \node at (2.25, 2.25) {$\alpha$};
    \node [below] at (2,0) {$x_1$};
    \node [left] at (0,1.5) {$x_2$};
    \draw[dashed](2,0) -- (X);
    \draw[dashed](0,1.5) -- (X);

\end{tikzpicture}
\end{center}
Toto nebudeme dokazovať teraz, ale dokážeme to neskôr.
\end{priklad}

\begin{priklad}[Osová súmernosť podľa priamky]
Uvažujme maticu $B = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}$ a počítajme pre $\vec{x}=(x_1, x_2)$ máme
$$ [[B]](\vec{x}) = B\vec{x} = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} x_2 \\ x_1 \end{pmatrix} $$
Toto zobrazenie teda vymieňa zložky. Geometricky sa toto dá vyjadriť ako osová súmernosť
podľa priamky $q$, ktorú už poznáme \eqref{eq:q}
\begin{center}
\begin{tikzpicture}
[
    >=Stealth, % Sets the default arrow tip style
    x=1cm, y=1cm, % Sets the scale
    axis/.style={->, thick},
    vec/.style={->, thick, -{Stealth[length=2.5mm]}},
    dashline/.style={dashed, thick}
]
    % Osi
    \draw [->, thick] (-1,0) -- (4,0) node [right] {$x_1$};
    \draw [->, thick] (0,-1) -- (0,4) node [above] {$x_2$};
\foreach \x in {1,2,3} {
    \draw (\x, 2pt) -- (\x, -2pt) node[below, yshift=-2pt] {$\x$};
}
\foreach \y in {1,2,3} {
    \draw (2pt, \y) -- (-2pt, \y) node[left, xshift=-2pt] {$\y$};
}

    
    % Priamka q (os symetrie)
    \draw [red] (-1,-1) -- (4,4) node [right] {$q$};
    
    % Vektor x
    \coordinate (A) at (3,1);
    \draw [vec] (0,0) -- (A) node [right, black] {$(3,1)$};
    
    % Vektor B(x)
    \coordinate (B) at (1,3);
    \draw [vec] (0,0) -- (B) node [above, black] {$[[B]](3,1)$};
    
    % Pociatok
    \fill (0,0) circle (1.5pt) node [below left] {$(0,0)$};
    \draw [dashline] (A) -- (A |- 0,0); 
    \draw [dashline] (A) -- (0,0 |- A); 
    \draw [dashline] (B) -- (B |- 0,0); 
    \draw [dashline] (B) -- (0,0 |- B); 
    \draw [dashline,->, >=Stealth, blue] (A)--(B);
\end{tikzpicture}
\end{center}
\end{priklad}

\subsection{Ktoré zobrazenia sú reprezentovateľné maticami?}
V tomto momente vzniká prirodzená otázka, ktoré zobrazenia $\mathbb{R}^n \rightarrow \mathbb{R}^m$ sú reprezentovateľné maticami $R^{m \times n}$;
väčšina toho, čo sa budeme učiť vo zvyšku tohto semestra sa bude týkať hľadania systematickej odpovede na túto otázku.
Zatiaľ sa obmedzíme na konštatovanie, že nie všetky zobrazenia $\mathbb{R}^n \rightarrow \mathbb{R}^m$ sú reprezentovateľné maticou.
Napríklad iste platí, že $A\vec{0} = \vec{0}$ pre každú
maticu $A$. Teda ľubovoľné zobrazenie, ktoré
zobrazí vektor $\vec{0}$
na nenulový vektor iste
reprezentovateľné maticou nebude.

\subsection{Súčin matíc je reprezentácia zloženého zobrazenia}
\begin{veta}\label{veta:nasobenieMatic}
Nech $A \in \mathbb{R}^{m \times n}, B \in \mathbb{R}^{k \times m}$.
Uvažujme zobrazenia reprezentované maticami $A, B$.
$$ [[A]]: \mathbb{R}^n \rightarrow \mathbb{R}^m $$
$$ [[B]]: \mathbb{R}^m \rightarrow \mathbb{R}^k $$
Potom zložené zobrazenie $[[B]] \circ [[A]]$ je práve zobrazenie asociované s maticou
$BA$:
\[
[[B]] \circ [[A]] = [[B A]]
\]
\end{veta}
\begin{proof}
Máme dokázať, že $[[B]] \circ [[A]] = [[B A]]$.
Obe tieto zobrazenia sú typu $\mathbb{R}^n \rightarrow \mathbb{R}^k$. Nech $\vec{x} \in \mathbb{R}^n$.
\begin{align*}
([[B]] \circ [[A]])(\vec{x}) &= [[B]]([[A]](\vec{x})) & \text{(definícia zloženého zobrazenia)} \\
&= [[B]](A\vec{x}) & \text{(predpis pre $[[A]]$)} \\
&= B(A\vec{x}) & \text{(predpis pre $[[B]]$)} \\
&= (B A)\vec{x} & \text{(asociativita násobenia matíc)} \\
&= [[B A]](\vec{x}) & \text{(predpis pre $[[BA]]$)}
\end{align*}
Zobrazenia $[[BA]]$ a $[[B]] \circ [[A]]$ majú rovnaký definičný obor aj koobor a
každý vektor $\vec{x} \in \mathbb{R}^n$ zobrazia na rovnaký vektor v $\mathbb{R}^k$.
To znamená, že $[[B]] \circ [[A]] = [[BA]]$.
\end{proof}

\begin{priklad}
Uvažujme maticu rovinnej rotácie $L_{\frac{\pi}{2}}$:
$$L_{\frac{\pi}{2}}= \begin{pmatrix} \cos\frac{\pi}{2} & -\sin\frac{\pi}{2} \\ \sin\frac{\pi}{2} & \cos\frac{\pi}{2} \end{pmatrix} = \begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix} $$
$$ L_{\frac{\pi}{2}} L_{\frac{\pi}{2}} = \begin{pmatrix} 0 & -1 \\ 1 & 0
\end{pmatrix} \begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix} = \begin{pmatrix} -1 & 0
\\ 0 & -1 \end{pmatrix} 
=D_{-1}
$$
Táto matica by mala reprezentovať zložené zobrazenie $[[L_{\frac{\pi}{2}}]] \circ
[[L_{\frac{\pi}{2}}]]$, teda zobrazenie
$[[L_{\frac{\pi}{2}+\frac{\pi}{2}}]]=[[L_\pi]]$.
Matica $D_{-1}$ reprezentuje zobrazenie násobenie skalárom $-1$. Ale vynásobiť
rovinný vektor skalárom $-1$ je to isté ako otočiť ho o $\pi$ vľavo (alebo vpravo), teda $D_{-1} = L_{\pi}$.
\end{priklad}

\begin{priklad}
Ak vezmeme pravouhlú projekciu $P$ na priamku $q$ (viď vyššie), očakávame, že
$PP = P$, pretože $[[P]]\circ [[P]]=[[P]]$.
Naozaj:
$$ \begin{pmatrix} 1/2 & 1/2 \\ 1/2 & 1/2 \end{pmatrix} \begin{pmatrix} 1/2 & 1/2 \\ 1/2 & 1/2 \end{pmatrix} = \begin{pmatrix} 1/4+1/4 & 1/4+1/4 \\ 1/4+1/4 & 1/4+1/4 \end{pmatrix} = \begin{pmatrix} 1/2 & 1/2 \\ 1/2 & 1/2 \end{pmatrix} $$
\end{priklad}

%D.Ú.: Nájdite geometrickú interpretáciu zobrazenia $P \circ D_2$. Kreslite si obrázky.
%V akom vzťahu sú zobrazenia $P \circ D_2$ a $D_2 \circ P$?
%Z toho vyplýva, presvedčte sa $P D_2 \neq D_2 P$.

%D.Ú.: Ukážte, že $L_{\alpha} \circ P \neq P \circ L_{\alpha}$ a vypočítajte aj príslušné matice zložených zobrazení.

\subsection{Inverzná matica}
\begin{definicia}\label{def:inverzna}
Nech $A$ je štvorcová matica typu $n \times n$. \emph{Inverzná matica k
$A$} je taká matica $A^{-1}$ typu $n \times n$, pre ktorú platí 
$$ A A^{-1} = A^{-1} A = I_n $$
\end{definicia}
Pozor! Inverzná matica k štvorcovej matici nemusí existovať. Napríklad nulová matica iste nemá inverznú, prečo?

\begin{definicia}
Nech $A$ je štvorcová matica. Ak $A$ má inverznú, hovoríme, že $A$ je
\emph{regulárna}. V opačnom prípade hovoríme, že $A$ je \emph{singulárna}.
\end{definicia}
\begin{priklad}
Ak 
\[
A = \begin{pmatrix}
1 & 1 & 1 \\
1 & 2 & 1 \\
-3 & -6 & -2
\end{pmatrix}
\]
potom inverzná matica k $A$ je
\[
A^{-1} = \begin{pmatrix}
2 & -4 & -1 \\
-1 & 1 & 0 \\
0 & 3 & 1
\end{pmatrix}
\]
\end{priklad}

\begin{priklad}[Inverzná rotácia]
\[
L_{-\alpha} = \begin{pmatrix} \cos(-\alpha) & -\sin(-\alpha) \\ \sin(-\alpha) & \cos(-\alpha) \end{pmatrix} = \begin{pmatrix} \cos\alpha & \sin\alpha \\ -\sin\alpha & \cos\alpha \end{pmatrix}
\]
je inverzná matica k $L_{\alpha}$.
\end{priklad}

Keďže $A, A^{-1}$ sú štvorcové rovnakého typu, povedzme $A, A^{-1} \in \mathbb{R}^{n \times n}$, reprezentujú nejaké zobrazenia
$$ [[A]]: \mathbb{R}^n \rightarrow \mathbb{R}^n $$
$$ [[A^{-1}]]: \mathbb{R}^n \rightarrow \mathbb{R}^n $$
Definícia inverznej matice hovorí, že
$$ A A^{-1} = A^{-1} A = I_n $$
Keďže tieto sú matice, sú rovnaké aj nimi reprezentované zobrazenia sú rovnaké
$$ [[A A^{-1}]] = [[A^{-1} A]] = [[I_n]] $$
Podľa Vety \ref{veta:nasobenieMatic} ale
$$ [[A A^{-1}]] = [[A]] \circ [[A^{-1}]] $$
$$ [[A^{-1} A]] = [[A^{-1}]] \circ [[A]] $$
a vieme, že
$$ [[I_n]] = \id_{\mathbb{R}^n} $$
Z toho dostávame rovnosť zobrazení
$$ [[A]] \circ [[A^{-1}]] = [[A^{-1}]] \circ [[A]] = \id_{\mathbb{R}^n} 
$$
Ale to presne znamená, že $[[A^{-1}]]$ je zobrazenie inverzné k zobrazeniu $[[A]]$,
viď Definícia \ref{def:inverzneZobrazenie}.

\begin{veta}[Inverzia matice je inverzia zobrazenia]
Nech $A \in \mathbb{R}^{n \times n}$ je regulárna matica. Potom $[[A^{-1}]]$ je inverzné zobrazenie k zobrazeniu $[[A]]$.
Kompaktne to môžeme zapísať ako
$$ [[A^{-1}]] = [[A]]^{-1} $$
\end{veta}

\subsection{Inverzia súčinu matíc}

\begin{veta}
Nech $A, B$ sú regulárne matice rovnakého typu. Vtom aj $AB$ je regulárna matica a~platí $(AB)^{-1} = B^{-1}A^{-1}$.
\end{veta}

\begin{proof}
\begin{align*}
(AB) \cdot (B^{-1}A^{-1}) &= A (B B^{-1}) A^{-1} = A I A^{-1} = A A^{-1} = I \\
(B^{-1}A^{-1}) \cdot (AB) &= B^{-1} (A^{-1} A) B = B^{-1} I B = B^{-1} B = I
\end{align*}
\end{proof}

\textbf{POZOR:} Nič podobné neplatí pre súčet matíc.

\subsection{Počítanie inverznej matice}
Postup: napíšeme si vedľa seba maticu, ktorú chceme invertovať a jednotkovú maticu, oddelíme čiarou.
$$ ( A | I_n ) $$
(typu $n \times 2n$)
potom používame na obe matice (celé riadky) rovnaké elementárne riadkové operácie, ktorými sa snažíme upraviť maticu vľavo od čiary tak, aby sme tam dostali $I_n$. Ak sa nám to podarí, napravo od čiary máme $A^{-1}$.
$$ ( I_n | A^{-1} ) $$

\begin{priklad}
Takto sa to urobí pre konkrétnu maticu.
\[
\left[
\begin{array}{ccc|ccc}
1 & 1 & 1 & 1 & 0 & \tikzmarknode{r1a}{0} \\
1 & 2 & 1 & 0 & 1 & \tikzmarknode{r2a}{0} \\
-3 & -6 & -2 & 0 & 0 & 1
\end{array}
\right]
\begin{tikzpicture}[remember picture, overlay]
    \draw[->, thick, shorten >=2pt]
        ([xshift=1.5em]r1a.east)
        -- ++(1em,0) coordinate (corner)
        -- (corner |- r2a.east)
        node [midway, right] {$-1$}
        -- ([xshift=1.5em]r2a.east);
\end{tikzpicture}
\hspace{3.5em} \sim \quad
\left[
\begin{array}{ccc|ccc}
1 & 1 & 1 & 1 & 0 & \tikzmarknode{r1b}{0} \\
0 & 1 & 0 & -1 & 1 & 0 \\
-3 & -6 & -2 & 0 & 0 & \tikzmarknode{r3b}{1}
\end{array}
\right]
\begin{tikzpicture}[remember picture, overlay]
    \draw[->, thick, shorten >=2pt]
        ([xshift=1.5em]r1b.east)
        -- ++(1em,0) coordinate (corner)
        -- (corner |- r3b.east)
        node [midway, right] {$3$}
        -- ([xshift=1.5em]r3b.east);
\end{tikzpicture}
\hspace{3.5em} \sim \quad
\]
\[
\left[
\begin{array}{ccc|ccc}
1 & 1 & 1 & 1 & 0 & \tikzmarknode{r1c}{0} \\
0 & 1 & 0 & -1 & 1 & \tikzmarknode{r2c}{0} \\
0 & -3 & 1 & 3 & 0 & 1
\end{array}
\right]
\begin{tikzpicture}[remember picture, overlay]
    \draw[->, thick, shorten >=2pt]
        ([xshift=1.5em]r2c.east)
        -- ++(1em,0) coordinate (corner)
        -- (corner |- r1c.east)
        node [midway, right] {$-1$}
        -- ([xshift=1.5em]r1c.east);
\end{tikzpicture}
\hspace{3.5em} \sim \quad
\left[
\begin{array}{ccc|ccc}
1 & 0 & 1 & 2 & -1 & 0 \\
0 & 1 & 0 & -1 & 1 & \tikzmarknode{r2d}{0} \\
0 & -3 & 1 & 3 & 0 & \tikzmarknode{r3d}{1}
\end{array}
\right]
\begin{tikzpicture}[remember picture, overlay]
    \draw[->, thick, shorten >=2pt]
        ([xshift=1.5em]r2d.east)
        -- ++(1em,0) coordinate (corner)
        -- (corner |- r3d.east)
        node [midway, right] {$3$}
        -- ([xshift=1.5em]r3d.east);
\end{tikzpicture}
\hspace{3.5em} \sim \quad
\]
\[
\left[
\begin{array}{ccc|ccc}
1 & 0 & 1 & 2 & -1 & \tikzmarknode{r1e}{0} \\
0 & 1 & 0 & -1 & 1 & 0 \\
0 & 0 & 1 & 0 & 3 & \tikzmarknode{r3e}{1}
\end{array}
\right]
\begin{tikzpicture}[remember picture, overlay]
    \draw[->, thick, shorten >=2pt]
        ([xshift=1.5em]r3e.east)
        -- ++(1em,0) coordinate (corner)
        -- (corner |- r1e.east)
        node [midway, right] {$-1$}
        -- ([xshift=1.5em]r1e.east);
\end{tikzpicture}
\hspace{3.5em} \sim \quad
\left[
\begin{array}{ccc|ccc}
1 & 0 & 0 & 2 & -4 & -1 \\
0 & 1 & 0 & -1 & 1 & 0 \\
0 & 0 & 1 & 0 & 3 & 1
\end{array}
\right]
\]
\end{priklad}

\subsection{Sústavy lineárnych rovníc - nový pohľad}

Prizrime sa na sústavy lineárnych rovníc v kontexte zobrazení asociovaných z maticami.
Každá matica $A \in \R^{m \times n}$ nám určuje zobrazenie $[[A]]: \R^n \to \R^m$
predpisom $[[A]](\vec{x}) = A\vec{x}$.
Ak si predpis pre $[A]$ rozpíšeme do zložiek, dostaneme, pre $\vec{x} = (x_1, \dots, x_n) \in \R^n$, $A = (a_{ij})_{m \times n} \in \R^{m \times n}$:

$$ [[A]](\vec{x}) = \begin{pmatrix} a_{11} & a_{12} & \dots & a_{1n} \\ a_{21} & a_{22} & \dots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{m1} & a_{m2} & \dots & a_{mn} \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix} = \begin{pmatrix} a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n \\ a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n \\ \vdots \\ a_{m1}x_1 + a_{m2}x_2 + \dots + a_{mn}x_n \end{pmatrix} $$

To je ale presne a~doslova to, čo poznáme pod menom ľavá strana sústavy lineárnych
rovníc! Ak teraz vezmeme nejaký vektor $\vec{b} = (b_1, \dots, b_m)$, tak
$[[A]](\vec{x}) = \vec{b}$ presne znamená:

\begin{align*}
 a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n &= b_1 \\
 a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n &= b_2 \\
 \vdots \qquad \qquad \qquad \qquad & \\
 a_{m1}x_1 + a_{m2}x_2 + \dots + a_{mn}x_n &= b_m
\end{align*}

čo je doslova sústava lineárnych rovníc. Vidíme teda, že (pre danú maticu $A$ a~vektor $\vec{b}$)
je to isté:

\begin{center}
    \begin{minipage}[c]{0.4\textwidth}
        \centering
        vyriešiť \\
        sústavu lineárnych \\
        rovníc $(A|\vec{b})$
    \end{minipage}
    \begin{minipage}[c]{0.1\textwidth}
        \centering
        $\Leftrightarrow$
    \end{minipage}
    \begin{minipage}[c]{0.4\textwidth}
        \centering
        nájsť množinu \\
        všetkých vektorov $\vec{x}$ \\
        takých, že $[A](\vec{x}) = \vec{b}$, resp. $A\vec{x} = \vec{b}$
    \end{minipage}
\end{center}

\subsection{Jednotkové vektory v $\R^n$}

Zaveďme novú notáciu: v~$\R^n$ budeme označovať $\vec{e}_1, \dots, \vec{e}_n$ vektory:
\begin{align*}
 \vec{e}_1 &= (1, 0, \dots, 0, 0) \text{} \\
 \vec{e}_2 &= (0, 1, \dots, 0, 0) \text{} \\
 \vdots \quad & \\
 \vec{e}_n &= (0, 0, \dots, 0, 1) \text{}
\end{align*}
Všimnime si, že sú to presne stĺpce jednotkovej matice $I_n$; $s_i(I_n) = \vec{e}_i$ a~môžeme teda písať
$$ I_n = (\vec{e}_1 \vec{e}_2 \dots \vec{e}_n) $$

\subsection{Prečo funguje algoritmus počítania inverznej matice}

Spomeňme si, ako sme počítali sústavy lineárnych rovníc: pomocou elementárnych riadkových operácií sme upravovali ľavú stranu na stupňovitý tvar.
Potom sme robili ,,spätné dosádzanie''. Mohli sme ale postupovať aj trochu inak: pred fázou spätného dosádzania vynulovať aj prvky nad diagonálou:
$$ \left( \begin{array}{ccccc|c}
\blacksquare & 0 & 0 & \dots & 0 & \blacksquare \\
0 & \blacksquare & 0 & \dots & 0 & \blacksquare \\
0 & 0 & \blacksquare & \dots & 0 & \blacksquare \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \dots & \blacksquare & \blacksquare
\end{array} \right) $$
to by nám spätné dosádzanie výrazne zjednodušilo.

Najlepší prípad je ten, keď máme $n$ rovníc o~$n$ neznámych a~na ľavej strane nám vyjde diagonálna matica. Vtedy môžeme postupovať ďalej a~podeliť každý riadok diagonálnym prvkom.
Vtedy nám na pravej strane vyjde priamo riešenie sústavy, a~na ľavej strane máme jednotkovú maticu.
$$ (A|\vec{b}) \sim \dots \sim (I|\vec{x}) $$
Ak sa nám toto teda podarí, našli sme (jediný) vektor taký, že $A\vec{x} = \vec{b}$ a~je to presne pravá strana po eliminácii matice sústavy na jednotkovú.

Pozrime sa teraz z~novej perspektívy na algoritmus počítania inverznej matice:
$$ (A|I_n) \sim \dots \sim (I_n|Y) $$

\begin{center}
na tento postup môžeme nahliadať ako na \\
súbežné riešenie $n$ sústav lineárnych rovníc \\
$(A|\vec{e}_1), \dots, (A|\vec{e}_n)$
\end{center}

\begin{center}
\begin{tabular}{p{0.45\textwidth} p{0.45\textwidth}}
o tejto matici $Y$ tvrdíme, že je inverzná k $A$; označme jej stĺpce $\vec{y}_1, \dots, \vec{y}_n$ & $\vec{y}_i$ je riešenie sústavy $(A|\vec{e}_i)$, pre $i \in \{1, \dots, n\}$ \\
$Y = (\vec{y}_1 \dots \vec{y}_n)$ & $\Downarrow$ \\
& znamená, že $A\vec{y}_i = \vec{e}_i$ pre $i \in \{1, \dots, n\}$
\end{tabular}
\end{center}

Ak si teraz uvedomíme, ako sa násobia matice (napravo postupujeme po stĺpcoch), môžeme nahliadnuť, že toto znamená:
$$ A \cdot \underbrace{(\vec{y}_1 \dots \vec{y}_n)}_{\text{Toto je } Y \text{}} = (A\vec{y}_1 \dots A\vec{y}_n) = \underbrace{(\vec{e}_1 \dots \vec{e}_n)}_{\text{Toto je } I_n \text{}} \implies AY = I_n $$

V poriadku, ale prečo platí aj $YA = I_n$?
Aby sme to dokázali, je vhodné zaviesť pojem elementárnej matice:

\begin{definicia}[Elementárna matica]
$E$ je elementárna matica, ak vznikla z~jednotkovej matice $I$ vykonaním jednej elementárnej riadkovej operácie.
\end{definicia}

Napríklad pre pripočítanie $\frac{1}{2}$-násobku prvého riadku $I_3$ k~druhému dostaneme:
$$ \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{pmatrix} \xrightarrow{r_2 \leftarrow r_2 + \frac{1}{2}r_1} \begin{pmatrix} 1 & 0 & 0 \\ \frac{1}{2} & 1 & 0 \\ 0 & 0 & 1 \end{pmatrix} \to \text{elementárna matica} $$

Elementárne matice majú túto peknú vlastnosť: pre každú maticu $A$:

\begin{center}
\begin{tabular}{c c c}
$A \sim A'$ & $\Leftrightarrow$ & $A' = EA$ \\
$\uparrow$ & & $\uparrow$ \\
\parbox{4cm}{\centering elementárna riadková operácia} & & \parbox{5cm}{\centering toto je presne tá matica, ktorá vznikne z $A$ vykonaním elementárnej riadkovej operácie, ,,zakódovanej'' v $E$.}
\end{tabular}
\end{center}

Pri počítaní inverznej matice sa naľavo dialo toto:
$$ \underbrace{A \sim \dots \sim I_n}_{\text{elementárne riadkové operácie}} $$
Pomocou elementárnych matíc to môžeme zapísať takto:
\begin{equation} \label{eq:inv_left}
A \sim E_1 A \sim E_2 E_1 A \sim \dots \sim E_k \dots E_2 E_1 A = I_n
\end{equation}
Napravo sa zase dialo toto:
\begin{equation} \label{eq:inv_right}
I_n \sim E_1 I_n \sim E_2 E_1 I_n \sim \dots \sim E_k \dots E_2 E_1 I_n = E_k \dots E_2 E_1 = Y
\end{equation}
Z \eqref{eq:inv_left} a \eqref{eq:inv_right} zrejme dostávame $YA = I_n$.
Teda platí $AY = YA = I_n$
a~preto $Y = A^{-1}$, viď definícia inverznej matice \ref{def:inverzna}.


